## 선형회귀 정리
1. 선형 회귀
선형 회귀는 종속 변수 y와 하나 이상의 독립 변수 x와의 선형 상관관계를 모델링하는 기법이다. 만약 독립 변수 x가 1개라면 단순 선형 회귀라고 하고, 2개 이상이면 다중 선형 회귀라고 한다.

2. 단순 선형회귀

단순 선형 회귀는 y=Wx+b
의 식으로 나타난다. 머신러닝에서는 독립 변수 x에 곱해지는 W값을 가중치(weight), 상수항에 해당하는 b를 편향(bias)이라고 부른다. 

따라서 단순 선형 회귀 모델을 훈련하는 것은 적절한 W와 b값을 찾는 것이다. 그래프의 형태는 직선으로 나타난다. 

1. 산점도(scatter plot) 그리기
- 각 data point들을 2차원의 산점도로 나타내어 Linearity를 가지는지 시각화하여 눈으로 확인할 수 있다.

2. 회귀계수 추정

3. 유의성 검정
- 회귀모형 유의성은 (모든 기울기) = 0 을 검정하는 것과 같다. 
- 단순 선형 회귀모형은 p = 1인 경우로 beta_1 = 0 인지 검정한다.

4. 회귀모형의 평가
- 평균제곱근 오차(Root Mean Square Error) RMSE 는 추정 모형의 예측 정확도 평가를 위한 지표이다. 

- 예측치와 실측치의 차인 잔차를 이용해 만든다.


3. 다중 선형회귀

다중 선형 회귀는 y=W1x1+W2x2+...+Wnxn+b
의 식으로 나타난다. 여러 독립 변수에 의해 영향을 받는 경우이다. 만약 2개의 독립 변수면 그래프는 평면으로 나타날 것이다.
문제점 : 
1. 설명 변수의 정보 중첩으로 발생하는 다중공선성(multicollinearity) 문제

2. 너무 많은 설명 변수를 포함해 발생하는 차원의 저주 문제 등

- 회귀모형의 평가

평균제곱오차 = MSE(Mean Squared Error) 
: 모형을 통해 추정된 값(predict)과 실측값(ground truth) 의 차에 대한 제곱합의 평균으로 표현되며 이 값이 크면 모형의 예측력이 떨어짐을 의미하고, 이 값이 작을수록 모형이 더 정확한 예측을 한다는 것을 알 수 있다.


```python

```
