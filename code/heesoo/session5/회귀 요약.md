# 회귀 part 정리

    >회귀란? 
    : "연속형" 두 변수 간의 관계 분석, 무언가를 예측하라기 위해 사용하는 방식
    
    
    
    >선형 회귀(Linear Regression): probably approximately correct 한 target 함수를 학습하는 과정.
        >새로운 data가 생겼을 때, 적절한 선형 funtion을 만들어서 그 안에 있을 것으로 예상 가능하다. 그러나, 선형 함수는 현실에 다른 영향을 미치는 변수들에 의해 극히 드물다. 
        
    >단순 회귀(Simple Linear Regression): 연속형 반응 변수 y와 설명 변수 x 하나를 갖는 모형. 
        > 두 변수가 인과관계가 있고, x에 따라 y 값이 변한다는 가정 하에 모형을 그릴 수 있다. 
        
        1. 산점도 그리기: 각 데이터 포인트들을 2차원의 산점도로 나타내어 시각화할 수 있다.
        
        2. 회귀계수 추정: 오차가 최소가 되는 회귀계수를 찾아내는 ans 방식을 사용한다. 
        
        3. 유의성 검정: 
        모형 유의성-> 회귀 모형 유의성은 (모든 기울기) = 0 을 검정하는 것과 같다.  
        계수 유의성-> 모형이 유의하다고 해도 각 기울기도 모두 유의미하다고 말할 수는 없기에 각 회귀계수에 대한 유의성 검정을 통해 각 변수의 중요도 및 유의성을 확인할 수 있다. 
        
        4. 회귀 모형의 평가: 평균 제곱근의 오차는 추정 모형의 예측 정확도 평가를 위한 지표이다. 
        
    > 다중 선형 회귀(Multiple Linear Regression): 단순 선형 회귀 모형의 확장으로 연속형 반응 변수 하나에 설명 변수가 둘 이상인 모형을 말한다. 
        > 설명 변수가 늘어나 추가로 검토해야 할 문제가 발생한다. (ex: 설명 변수의 정보 중첩으로 발생하는 다중 공선성 문제 및 너무 많은 설명 변수의 포함으로 발생하는 차원의 저주 문제 등)
        >다중 공선성: 모형에 포함된 설명 변수의 정보 중첩으로 발생
        범주형 설명 변수: 다수의 설명 변수를 사용하면 범주형 설명 변수가 모형에 포함되는 경우가 존재
        변수 선택: 너무 많은 변수는 모형 과적합 야기


```python

```


```python

```
