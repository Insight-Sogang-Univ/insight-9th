
# 3차 교육세션 예습   
--- 
## 데이터 읽기
### 1. 절대경로: 처음부터 목적지까지의 전체적인 경로(URL)
    특징: 절대적 경로이기 때문에 누구나 알 수 있음
          최상위 /를 포함하고 있음
### 2. 상대경로: 현재 위치를 기준으로 한 목적지까지의 상대적 경로
    특징: 누가, 어디서 시작하느냐에 따라 도착지 달라짐
          최상위 /를 거치지 않고도 이동 가능
          - 최상위 디렉토리 "/"
          - 현재 디렉토리 "./"
          - 현재 디렉토리의 상위 디렉토리 "../"
### 3. CSV와 EXCEL 파일

- csv 파일(데이터를 쉼표로 구분하는 텍스트 파일)     
    - 데이터 크기가 작고 압축 용이 -> 가장 널리 사용
    - 텍스트 형식 -> 메모장과 엑셀로 열기 가능
    - cf. tsv는 tab으로 구분되어 있는 데이터     
---
- excel 파일(행과 열이 데이터프레임의 행, 열로 일대일 대응됨)     
  - 시트가 여러 개인 데이터이면 불러올 시트 설정 가능 (sheet_name='sheet2')
  - 여러 sheet 불러올 땐 list로 받자!! (sheet_name=['Sheet1','Sheet2'])      
---
- 파일 형식 별 읽고 쓰는 함수     
  - CSV: read_csv , to_csv
  - JSON: read_json, to_json
  - HTML: read_html, to_html
  - MS EXCEL: read_excel, to_excel
  - SQL: read_sql, to_sql
---
## 데이터 전처리
- 데이터 품질은 데이터 분석의 정확도에 중요한 요소
- 전처리: 누락 데이터, 중복 데이터 등 오류 수정 및 변형 과정
- 전처리 순서: 데이터 셋 확인 -> 결축값 처리 -> 이상값 처리 -> Feature Engineering      
 *Feature engineering: 도메인 지식을 이용해 특징을 추출하는 것     

### 1. 누락 데이터(결측치) 처리
(1) 누락데이터 확인
- info() -> 각 열의 유효한 값의 개수 보여줌
- value_counts(dropna=False) -> 각 열의 NaN 개수 보여줌
- isnull() -> 누락데이터 True, 유효 데이터 False   
  *df.isnull().sum()으로 자주 사용함~!
- notnull() -> 유효데이터 True, 누락데이터 False    

(2) 결측값 처리
- 삭제: 결측값이 무작위로 발생한 경우 사용
- 대체: 평균값, 최빈값 등 데이터의 분포와 특성을 잘 나차낼 수 있는 값을 활용하여 누락데이터를 대체, fillna() 사용

### 2. 중복 데이터 처리
- 하나의 데이터 셋에서 2개 이상 중복되는 경우 결과 왜곡 -> 중복 데이터 확인 필수 !!
- 확인: df['열1'].duplicated()
- 제거: df['열2'].drop_duplicates

### 3. 이상치 처리
- 이상치: 기존 데이터들과 거리가 먼 데이터
- 이상치 확인   
  - df.describe() 
  - 시각화 통해 확인 (BoxPlot)
  - Turkey Fences
- 이상치 처리   
  - 전체 삭제 : 이상값이 human error에 의해 발생한 경우
  - 다른 값으로 대체: 절대적인 관측치의 숫자가 작은 경우(단순삭제를 하면 관측치의 절대량이 작아지니까)
  - 변수화: 이상값이 자연 발생한 경우 -> 바로 삭제하지 말고 좀 더 이상값에 대해 파악해 보기
  - 리샘플링 : 자연 발생한 이상값을 처리하는 또 다른 방법

### 4. 범주형 데이터 처리
- 일정한 구간으로 나눠서 분석해보는 것
- 구간 분할(binning)
- 더미 변수(binning과 반대로 범주형 변수를 연속형 변수로 변환)

### 5. 정규화
- 숫자의 상대적 크기 차이로 인한 결과 왜곡 방지 목적
- 각 열에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 것
- Log 함수 (가장 자주 사용)
- Square root  

(1) StandardScaler: 각 feature의 평균을 0, 분산을 1로 변경하여 모든 특성들이 같은 스케일을 갖게 됨.   
(2) MinMaxScaler:  모든 feature가 0과 1 사이에 위치하게 만듦   
(3) RobustScaler: 모든 특성들이 같은 크기를 가짐(StandardScaler와 비슷) but, 평균과 분산 대신 median과 quartile 사용




