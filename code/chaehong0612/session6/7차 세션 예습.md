# 분류 이론, 실습

## 머신러닝의 개요  

머신러닝은 지도학습, 비지도학습, 강화학습으로 나뉜다.  

**1. 지도학습** : 
정답을 알고 있는 데이터를 이용해서 컴퓨터를 학습시킨다. 컴퓨터는 자신의 답과 정답의 차이를 지속적으로 개선하며 학습한다.  
회귀, 분류 등의 머신러닝 기법들이 여기에 해당한다.  

**2. 비지도학습** :  
정답이 없이 주어진 데이터로만 학습한다. 군집화, 밀도추정, 차원축소가 비지도학습에 해당한다.  

**3. 강화학습** :  
역동적인 환경에서 반복적인 시행착오 상호작용을 통해 작업 수행 방법을 학습하는 머신러닝 기법의 한 유형이다.  

## 분류  

**기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것**  

직접 데이터를 분류할 수도 있지만 데이터 수가 너무 많으면 분류하는데 한계가 있다.  
더불어 자료의 차원이 2차원이 아닌 n차원으로 확장이 된다면, 머신러닝 학습을 통해서 분류하는 것이 더 좋다.  

> **<분류의 대표적인 머신러닝 알고리즘>**  
    1. 로지스틱스 회귀 : 독립변수와 종속변수의 선형 관계성에 기반  
    2. 결정 트리 : 데이터 균일도에 따른 규칙 기반  
    3. 서포트 벡터 머신 : 개별 클래스 간의 최대 마진을 효과적으로 찾아줌  
    4. 최소 근접 알고리즘 : 근접 거리를 기준으로 함  

### 로지스틱스 회귀  

이벤트가 발생할 확률을 결정하는 데 사용되는 통계 모델로, 특성 간의 관계를 보여주고 특정 결과의 확률을 계산한다.  
이진 로지스틱 회귀, 다항 로지스틱 회귀, 순서 로지스틱 회귀 등이 있으며 다양한 분야에 적용되고 있다.  

### 결정 트리  

분류(Classification)와 회귀(Regression) 모두 가능한 지도 학습 모델 중 하나다.  
스무고개 하듯이 예/아니오 질문을 이어가며 학습한다는 특징이 있다.  
특정 기준(질문)에 따라 데이터를 구분하는 모델을 결정 트리 모델이라고 한다.  

### 서포트 벡터 머신  

주어진 데이터가 어느 카테고리에 속할지 판단하는 이진 선형 분류 모델이다.  
선과 가장 가까운 포인트를 서포트 벡터(Support vector)라고 한다. 즉, Margin은 구분하는 선과 서포트 벡터와의 거리를 의미한다.  
또한 이렇게 두 데이터를 구분하는 선을 Decision Boundary라고 부른다.  

### KNN (K-최소 근접 알고리즘)  

KNN 알고리즘은 데이터들 간의 유사한 특징을 기준으로 분류하는 알고리즘이다.  
주어진 데이터의 주변 이웃 데이터들의 특징을 파악하고 가장 유사한 데이터 그룹에 포함되도록 하는 방식이다.  
몇 개의 데이터를 이웃 집단으로 분류하여 어느 집단에 들어가는지가 중요하게 작용한다.  

- 장점 :  

  훈련 속도가 매우 빠르다.  
  복잡한 타겟 함수를 학습할 수 있다.  
  정보의 손실이 없다.  
  
  
- 단점 :  

  테스트하는데 걸리는 시간이 느리다.  
  매우 큰 용량을 요구한다.  
  관계없는 attribute나 이상치에 대해서 강건하지 않다.  


```python

```
