# 회귀 이론, 실습

관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한 뒤 적합도를 측정해 내는 분석 방법  
연속형인 두 변수 간의 관계를 분석하고, 무언가를 예측할 때 사용한다. 

## 선형 회귀 (linear regression)

기계학습이란 본질적으로 'probably approximately correct'한 target 함수를 학습하는 과정이다.  
선형 회귀는 해당 target 함수를 선형의 함수로서 근사하는 방법  

target 함수를 각 feature 변수들의 선형 가중합이라고 생각할 수 있다.  
여러 데이터 포인트를 input하여 선형으로 output  

- **적절한 선형 함수를 어떻게 만들 것인가?**

반응 변수와 설명 변수의 선형 관계를 전제로 모형을 만든다.  
그러나 현실에서는 선형 관계로 설명되는 현상은 극히 드물다.

### 단순 선형 회귀 

- 연속형 반응 변수 $y$ 와 설명 변수 $x$ 하나를 갖는 모형  
- 두 변수는 인과관계가 있고, $x$의 값에 따라서 $y$값이 변한다.  
- 변수 설명 
  - ei : 오차 (i번째 관측치의 오차)
  - $\beta_0$, $\beta_1$ : 회귀 계수 
  > $\beta_1$은 $x$가 한 단위 변할 때 $y$의 변화를 의미하고, $\beta_0$는 $x$=0일 때 $y$의 기댓값을 나타낸다.

#### 산점도 그리기  

각 데이터들을 2차원의 산점도로 나타내어 선형성을 가지는지 시각화하여 확인할 수 있다.  
비선형 관계를 갖는다면 변수 변환 방법을 적용하여 선형 모형으로 바꾸는 것이 가능하다.  

#### 회귀 계수 추정  

회귀 계수를 추정하는 방법은 최소제곱법(최소차승법), 최대우도추정법 두 가지가 있다.  

- 최소제곱법 : 식을 각각 $\beta_1$과 $\beta_0$으로 편미분하여 0과 같다고 놓는다. 
- 최대우도추정법 : $\beta_1$과 $\beta_0$을 구하는 가장 이상적인 방법을 찾는다
  - ans : 주어진 데이터에 대해서 오차가 최소가 되는 $\beta_1$, $\beta_0$ 값을 구한다.
  - 오차 : 예측과 실제 값 사이의 차이  
  
#### 유의성 검정  

모형 유의성 - 모형에 포함된 모든 기울기가 0인지 검정하는 분산 분석 문제  
계수 유의성 - 각 게수 값이 0인지 검정하는 T-검정 문제  

**단순 선형 회귀모형은 설명 변수가 하나다 > 모형 유의성과 계수 유의성 검정이 같다.**  

- **회귀 모형 유의성**  

  회귀 모형 유의성은 (모든 기울기 = 0)을 검정하는 것과 같다.  
  단순 선형 회귀 모형은  $p=1$ 인 경우로 $\beta_1=0 $인지 검정한다.  
  
  모형 유의성은 분산 분석과 같이 각각을 자유도로 나눈 평균 변동을 기준으로 평가한다.    
  회귀 모형으로 설명되는 평균 변동이 오차로 설명되는 평균 변동보다 통계학적으로 유의한 수준으로 클수록 모형의 유의성은 높아진다.  
  

- **회귀 계수 유의성**  

  각 회귀계소에 대한 유의성 검정을 통해 각 변수의 중요도 및 유의성을 확인할 수 있다.  
  이때 각 기울기 유의성은 T-검정을 통해 얻을 수 있다.  
  
#### 회귀 모형의 평가  

평균제곱근 오차(RMSE) 는 추정 모형의 예측 정확도 평가를 위한 지표  

예측치와 실측치의 차인 잔차를 이용해 만든다.  

**RMSE** 
- 회귀선을 기준으로 실측치(ground truth) 가 얼마나 벗어나 있는지 나타내는 값  
  (작을수록 잘 회귀선이 fit 되어 있다는 뜻)  
  
- y 값의 단위에 영향을 받기 때문에 절대적인 측도로는 부족하고, 다른 측도가 필요하다.

### 다중 선형 회귀  

단순 선형 회귀모형의 확장으로 연속형 반응 변수 하나에 설명 변수가 둘 이상인 모형  
설명 변수가 늘어나기 때문에 추가로 검토해야 할 문제가 생긴다.

대표적으로는

- 설명 변수의 정보 중첩으로 발생하는 다중공선성(multicollinearity) 문제
- 너무 많은 설명 변수를 포함해 발생하는 차원의 저주 문제  

**다중공선성 (multicolinearity)**
    
모형에 포함된 설명 변수의 정보 중첩(상관관계를 가짐) 으로 발생  
공선성 확인을 통해 변수를 선택하거나 주성분 분석 등을 통한 차원 축소 방법으로 해결
    
**범주형 설명 변수 (qualitative predictors)**
    
다수의 설명 변수를 사용하면 범주형 설명 변수가 모형에 포함되는 경우가 존재  
범주형 설명 변수를 어떻게 다룰 것인가와 관련한 문제
 
**변수 선택 (variable selection)**  
    
너무 많은 변수는 모형 과적합(overfitting) 야기  
불필요한 변수를 제거하여 과적합을 막고 모형을 보다 강건(robust)하게 만드는 방법  

>**진행 방법**  
    
   1. scatter plot이 가능하다면 plot으로 선형성 확인  
   2. 회귀계수 추정 (오차 이용하는 것 동일)  
   3. 유의성 검정  
   4. 평가  

#### 회귀 모형의 가정 진단  

회귀모형은 반응 변수와 설명 변수의 선형 관계를 전제로 한다.  
또한 오차에 대한 독립성, 정규성, 등분산성 가정을 전제로 한다.  
앞서 확인한 모형의 유의성과 계수의 유의성이 확보되었다고 해도, 오차에 대한 가정을 만족하지 않으면 다른 대안을 찾아야 한다.  

**가정진단** : 내가 만든 linear regression 모델이 어느 정도 신빙성이 있음을 주장하기 위한 최소한의“근거”  

1. 선형성 진단  

   반응 변수와 설명 변수가 선형 관계임을 기본으로 하기 때문에 가장 기초가 되는 진단  
   scatter plot을 통해 서로 선형 관계인지를 먼저 확인하면 알 수 있다.  
   또는 상관계수를 이용하면 비선형 상관계수는 알 수 없지만, 선형 관계의 정도 및 유의성을 알 수 있다.  


2. 오차항의 독립성 진단  
 
    오차의 독립성 (independence) 문제는 관측치가 서로 상관되어 있을 때 발생  

    - 잔차 그래프
    - ACF 그래프
    - Durbin-Watson 통계량

   으로 독립성 문제를 진단할 수 있다.  
   
   
3. 오차항의 등분산성 진단  

   잔차 그래프와 등분산성 검정을 통해 알 수 있다.  
   잔차의 등분산성 검정을 통해 등분산성을 만족하는지 확인할 수 있다.  
   
   
4. 오차항의 정규성 진단  

   잔차에 대한 Q-Q Plot을 이용한 시각적 확인 방법과 정규성 검정을 통한 확인 방법이 있다.  
   
   -  Q-Q Plot : 표준화된 잔차가 Q-Q Plot의 대각선에 위치해 있으면 정규성 가정을 만족  
   - 정규성 검정 : K-S 통계랑, Cramer-von Mises 통계량 등을 이용  

### 회귀 모형의 평가  

- **평균 제곱 오차**  

MSE(Mean Squared Error) 또는 MSD(Mean Squared Deviation)라고 표현한다.  
모형을 통해 추정된 값(predict)과 실측값(ground truth) 의 차에 대한 제곱합의 평균으로 표현된다.  
이 값이 크면 모형의 예측력이 떨어짐을 의미, 이 값이 작을수록 모형이 더 정확한 예측  

### 선형 회귀 분석의 주요 이슈   

1. **dummy 변수**   

   수치로 표현이 되지 않는 경우에, 이를 모델에 포함하고 싶은 경우 사용  
   

2. **이상치**  

   관찰된 데이터의 속성과 많이 동떨어진 데이터, **왜 생겼는지 분석하는 것이 중요함!** 
   
  
3. **다중공선성**  

    설명 변수들 간의 선형 종속이 심한 경우, 설명 변수들 간 정보의 중첩이 발생  
    최소 제곱법으로 추정된 모형이 유일한 해를 갖지 않기 때문에 안정성이 매우 떨어진다.  
