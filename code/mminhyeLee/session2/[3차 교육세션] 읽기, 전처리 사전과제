# [3차 교육세션] 읽기, 전처리 사전과제

## 데이터 입출력

### 0. 절대경로와 상대경로
- 절대경로: 처음(파일의 root)부터 시작하여 목적지까지의 전체적인 경로(URL)를 의미
    - 시작 지점부터 목표지점까지 절대적으로 이곳을 가리키기에, 보통 문서나 파일을 이용할 때 사용
    - 최상위 /를 포함하는 것이 특징
    - ex) https://velog.io/@bami
- 상대경로: 현재 위치를 기준으로 한 목적지까지의 상대적 경로
    - 최상위 /를 거치지 않고도 이동이 가능
    - ex) ./src/compnent
    
### 1. Intro
- 파일의 형식에 따라 데이터를 읽고 쓰는 함수가 다름

### 2. CSV 파일
- 데이터의 크기가 작고 압축이 용이하기 때문에 가장 널리 사용되는 데이터 형식
- comma separated value: 데이터 값을 쉼표(,)로 구분하는 텍스트 파일
    - cf) tsv: tab separated value, tab으로 구분되어 있는 데이터
- 텍스트 형식이므로 메모장/엑셀로 열 수 있음
- **pandas.read_csv('파일경로(이름).csv')**

### 3. EXCEL 파일
- 행과 열이 데이터프레임의 행, 열로 일대일 대응
- 여러 개의 시트로 구성데이터를 불러올 때 불러올 시트를 설정할 수 있음
- 여러 sheet를 불러올 때는 list로 받으면 됨
    - ex) sheet_name = ['Sheet1', 'Sheet2']
    {'Sheet1': 데이터프레임1, 'Sheet2':'데이터프레임2'}인 dictionary 타입으로 return
- **pd.read_excel('파일경로.xlsx', engine = 'openpyxl')
  **pd.read_excel('./지하철 승하차 인원정보.xlsx', sheet_name ='20년 2월')
  
### 4. CSV 와 EXCEL 파일의 공통점
- 두 형식 모두 pandas를 통해 DataFrame 형식으로 읽어올 수 있음
    -`index_col` (```pd.read_csv('data/SeoulFloating.csv', index_col ='date').head()```)
        - 불러온 데이터 중 하나의 칼럼을 인덱스로서 설정함
        - 칼럼 설정은 인덱스 번호/ 칼럼 이름 모두 가능
    - `usecols` (```pd.read_csv('data/SeoulFloating.csv'), usecols=[0, 1].head()```)
        -데이터 중 원하는 칼럼만 선별하여 불러옴 (로드 후 칼럼 추출보다 메모리 절약)
        
## 전처리

- 정의: 데이터 분석의 정확도를 위해 누락 데이터, 중복 데이터 등 오류를 수정하고 본 목적에 맞게 변형하는 과정
- 순서: 데이터 셋 확인 => 결측값 처리 => 이상값 처리 => Feature Engineering
    - Feature Engineering? : domain knowledge를 이용해 특징을 추출하는 것

### 1. 누락데이터(결측치) 처리

#### 1) 누락데이터 확인
- info() 메소드로 데이터프레임의 요약정보를 출력하면, 각 열에 속하는 유효한 값(non-null, 즉 NaN 값이 아닌)의 개수 확인
- value_counts(dropna=False) 메소드를 이용해 각 열의 NaN값 개수 확인
- isnull(): 누락데이터면 True, 유효한 데이터면 False 반환
- notnull(): 유효데이터면 True, 누락데이터면 False 반환

#### 2) 결측값 처리
- 삭제
    - 전체삭제: 결측값이 발생한 모든 관측치를 삭제
        - 장점: 간편함
        - 단점: 관측치가 줄어들어 모델의 유효성 낮아짐
    - 부분삭제: 데이터 중 모델에 포함시킬 변수들 중 결측값이 발생한 모든 관측치 삭제
        - 단점: 모델에 따라 변수가 달라 관리비용이 늘어날 수 있음
    - 열 삭제: 분석대상이 갖는 특성(변수)를 삭제
    - 행 삭제: 분석대상의 관측값(레코드)을 제거
    - 주의) 삭제는 결측값이 무작위로 발생한 경우 사용! 무작위 발생이 아닌데 관측치를 삭제할 경우 왜곡된 모델 생성될 수 있음

- 대체
    - 누락데이터를 대체할 값으로 데이터의 분포와 특성을 잘 나타낼 수 있는 평균값, 최빈값 활용
    - fillna() 메소드 활용
        - 평균값 대체: df['열1'].fillna(a, inplace = True)
        - 직전 행 값으로 대체: df['열2'].fillna(method='ffill')
        - 다음 행 값으로 대체: df['열3'].fillna(method=' bfill')

### 2. 중복 데이터 처리
- 하나의 데이터 셋에서 2개 이상의 행이 중복되는 경우 결과를 왜곡하기에 확인 필요
    - 1) 확인 : df['열1'].duplicated()
    - 2) 제거 : df['열2'].drop_duplicates()

### 3. 이상치 처리
- 이상치: 기존 데이터들과 거리가 먼 데이터 

#### 이상치 확인
- 1) df.describe()
- 2) 시각화를 통해 확인 (BoxPlot)
- 3) Turkey Fences : 사분위 범위를 기반으로, 두 가지 경우에 이상치 판단
    - Q1 - (1.5 * IQR) 미만
    - Q3 + (1.5 * IQR) 초과

#### 이상치 처리
1. 전체 삭제
- 이상값이 Human error에 의해 발생한 경우, 해당 관측치를 **삭제**
- 단순 오타, 비현실적 응답, 데이터 처리과정 상 오류 등의 경우 사용

2. 다른 값으로 대체
- 절대적인 관측치의 숫자가 작응 경우, 단순삭제를 통해 이상치를 제거하면 관측치의 절대량이 작아지는 문제 발생
- 이런 경우 이상값이 Human error에 의해 발생했더라고 관측치를 삭제하는 대신 다른 값으로 **대체**, 결측값과 유사하게 다른 변수들을 사용해 예측 모델을 만들고, 이상값을 예측한 후 해당 값으로 대체하는 방법 사용 가능

3. 변수화
- 이상값이 자연발생한 경우, 단순 삭제나 대체의 방법을 통해 수립된 모델은 설명/예측하고자 하는 현상을 잘 설명하지 못할 수도 있음
- 자연발생적 이상값은 바로 삭제하지 말고 천천히 이상값에 대해 파악하는 것이 중요

4. 리샘플링
- 자연발생한 이상값에 대해 해당 이상값을 분리해서 모델 만들기

### 4. 범주형 데이터 처리
- 연속 데이터를 일정한 구간으로 나눠서 분석하는 방법
- 이산적인 값으로 나타내어 구간별 차이를 드러냄

1. 구간분할 (binning)
2. 더미변수
- 범주형 변수를 연속형 변수로 변환하기 위해 사용
- 카테고리를 나타내는 범주형 데이터를 회구분석 등 머신러닝 알고리즘에 바로 사용할 수 없기에, 인식 가능한 입력값으로 변환하는 과정
- 숫자 0 또는 1로 표현되는 더미변수(dummy variable)를 사용

### 5. 정규화
- 숫자의 상대적인 크기 차이로 인한 결과의 왜곡을 방지하기 위해 각 열(변수)에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 정규화(normalization)이 필요
    - 변수의 단위를 변경하고 싶거나 변수의 분포가 편향되어 있을 경우, 변수 간의 관계가 잘 드러나지 않는 경우에는 변수 변환의 방법 사용
    - 가장 자주 사용하는 방법으로는 log 함수, 덜 자주 사용되는 방법은 제곱근을 취하는 방법
    - 라이브러리 임포트
    
        1) StandardScaler
        - 각 feature의 평균을 0, 분산을 1로 변경하여, 모든 특성들이 같은 스케일을 가짐
        - 정규분포를 따른다고 가정하는 기술에 적합
        
        2) MinMixScaler
        - 모든 feature가 0과 1 사이에 위치
        - 데이터가 2차원 셋일 경우 모든 데이터는 x축의 0과 1 사이에, y축의 0과 1 사이에 위치
        - 데이터가 서로 다른 비율의 속성으로 구성되어있을 때, 같은 비율로 속성을 맞춤
        - 연산 속도를 높이고 알고리즘 최적화하는데 효과적
        
        3) RobustScaler
        - 모든 특성들이 같은 크기를 갖는다는 점에서 StandardScaler와 비슷하지만, 평균과 분산 대신 중간값과 사분위수를 사용
        - 이상치에 영향을 받지 않음. 



    


 
    