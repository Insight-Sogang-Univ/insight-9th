# 분류?

- 분류(Classification)란 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것

- 사용 이유
    - 데이터 수가 매우 많으면 손으로 분류하는 것도 한계 존재
    - 자료의 차원이 2차원이 아닌 n차원으로 확장이 된다면, 머신러닝 학습을 통해서 분류하는 것이 시간적으로 효율적 

- 종류
    1) 독립변수와 종속변수의 선형 관계성에 기반한 로지스틱 회귀(Logistic Regression)
    2) 데이터 균일도에 따른 규칙 기반의 결정 트리(Decision Tree)
    3) 개별 클래스 간의 최대 마진 분류 마진을 효과적 으로 찾아주는 서포트 벡터 머신(SVM)
    4) 근접 거리를 기준으로 하는 최소 근접(Nearest Neighbor) 알고리즘

## 로지스틱 회귀 Logjistic Regression
- X 데이터와 Y 데이터의 선형 관계성이 보장이 된다면, 사용하는 기법
- 연속형 변수가 아닌 범주형 변수로 사용 하는 회귀이기 때문에 하나의 분류 과정으로 취급 


## 결정 트리(Decision Tree)
- 규칙 노드 (Decision Node)에서 규칙에 따라 분할, 각각의 서브 트리(Sub Tree)를 생성
- 계속되는 규칙에 따라 노드가 분할, 최종적으로 리프 노드(Leaf Node)에서는 클래스 값을 가지게 됨
- 데이터가 주어졌을 때 각 노드의 단계를 거치며 분류를 하게 되며 마지막 노드에 도달했을 때 그 노드의 값으로 데이터의 클래스를 예측
- 규칙들이 계속적으로 늘어나면서 분류를 진행해 과적합(Overfitting)의 문제를 야기시키므로 적절하게 학습 필요


## 서포트 벡터 머신(Support Vector Machine)
- 딥러닝이 대두하기 전까지 가장 많이 활용되던 머신러닝 알고리즘
- 클래스를 분류할 수 있는 다양한 경계선 중 최적의 라인을 찾아내는 원리
- 장점:  명확하게 분류할 수 있는 데이터 집단에 적합, 고차원 공간에서도 효과적으로 사용 가능

## kNN(k - Nearest Neighbor)

- 데이터들 간의 유사한 특징을 기준으로 분류
- 주어진 데이터의 주변 이웃 데이터들의 특징을 파악하고 가장 유사한 데이터 그룹에 포함시키는 방식
- 장점
    - 빠른 훈련 속도
    - 복잡한 target 함수 학습 가능
    - 정보의 손실이 적음
- 단점
    - 쿼리하는 시간이 느림
    - 매우 큰 용량을 요구
    - 관계없는 attribute나 이상치에 대해 강건하지 않음