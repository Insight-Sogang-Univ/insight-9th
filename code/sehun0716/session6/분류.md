# 머신러닝 개요

1. 지도학습 
- 정답을 알고 있는 데이터를 이용해 컴퓨터를 학습 시킴. 컴퓨터는 자신의 답과 정답의 차이를 통해 지속해서 학습함
- 지도학습은 연속적인 숫자값을 예측하는 **회귀**와 입력된 데이터를 주어진 항목들로 나누는 **분류** 등 많은 머신러닝 기법들이 해당함
2. 비지도 학습
- 정답이 있지 않음
- 군집화, 밀도추정, 차원축소가 해당함<br>
3. 강화학습

> 분류: 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것

- 우리가 직접 2차원의 데이터를 분류해서 사용할 수도 있지만, 데이터 수가 너무 많으면 손으로 분류하는 것에 한계까 있음. 2차원이 아닌 n차원으로 확장될 시, 머신러닝이 더 좋음

# 분류의 대표적인 머신러닝 알고리즘
1. 로지스틱스 회귀: 독립 변수와 종속변수의 선형 관계성에 기반
2. 결정트리: 데이터 균일도에 따른 규칙 기반
3. 서포트 백터 머신: 개별 클래스 간의 최대 마진 분류 마진을 효과적으로 찾는 것
4. 최소 근접: 근접 거리를 기준으로

## 로지스틱스 회귀
- x데이터와 y데이터의 선형 관계성이 보장 된다면 사용하는 기법. 회귀라고 할 수도 있지만 연속형 변수가 아닌 범주형 변수로 사용하는 회귀
- odds: 임의의 사건 A가 발생하지 않은 확률 대비 일어날 확률의 비율
- 해당하는 유리함수를 그려보고 x축의 범위를 확률의 범위인 0과 1사이로 제약을 해보면 해당하는 함숫값들이 0에서 무한대 사이의 범위를 가짐
- 그런 함수에 log함수를 취하면 로지트 함수가 됨
- 로지트 함수의 정의역은 0~1, 치역은 음의 무한대에서 양의 무한대
- 사회현상에서는 특정 변수에 대한 확률값이 선형이 아닌 **S-커브 형태**를 따르는 경우가 많음. 이러한 S-커브를 함수로 표현해낸 것

## 결정트리
- 규칙 노드에서 규칙에 따라 분할되며 각각의 서브 트리를 생성
- 데이터가 주어졌을 떄 각 노드의 단계를 거치며, 분류를 하게 되며 마지막 노드에 도달 했을 때 그 노드의 값으로 데이터의 클래스를 예측하는 방식 
- 과적합의 문제를 야기시킬 수 있기에 적절하게 학습시켜야함

## 서포트 백터 머신
- 클래스를 분류할 수 있는 다양한 경계선이 존재하는데 그 중 최적의 라인을 찾아내는 원리
- 명확하게 분류할 수 있는 데이터 집단에서 뛰어난 성능, 고차원 공간에서도 효과적으로 사용 가능
- 궁극적 목적: 두 데이터 사이의 직선을 놓는 것(마진)
- 각 데이터들이 어느 레이블에 들어갈지를 구별하는 직선을 구하는 방법

## kNN
- 최소 근접 알고리즘: 데이터들 간의 유사한 특징을 기준으로 분류하는 알고리즘
- 주어진 데이터의 주변 이웃 데이터들의 특징을 파악하고 가장 유사한 데이터 그룹에 포함되도록 하는 방식
    1. 이점
    - 빠른 훈련 속도
    - 복잡한 함수 학습 가능
    - 정보 손실 없음
    
    2. 단점
    - 쿼리 시간이 느림
    - 매우 큰 용량을 요구
    - 관계 없는 attribute나 이상치에 대해 강건하지 않음
