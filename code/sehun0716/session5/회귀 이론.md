# 이론 설명

- 회귀
    - 입력을 받아 가장 적합한 숫자값을 예측하는 문제
    - 가장 기본적인 머신러닝 문제
- 분류
    - 분류에 해당하는 손실함수를 직접 최적화하여 푸는 방법 사용
    - 주어진 입력에 대하여 여러가지 항목들 중 제일 가능성이 높은 한 가지(혹은 여러가지) 선택
    - 멀티 클래스 분류: 여러 가지 항목 중 하나
    - 멀티 레이블 분류: 여러 가지 항목 중 복수
- 군집화
    - 비슷한 성격의 데이터를 묶는 것
- 표현형
    - 풀고자 하는 문제에 적합한 표현형을 데이터로부터 추출하는 것

# 회귀 분석
- 관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한 뒤 적합도를 측정해 내는 분석 방법
- 시간에 따라 변화하는 데이터나 어떤 영향, 가설적 실험, 인과 관계의 모델링 등의 통계적 예측에 이용 가능
- **연속형** 두 변수 간의 관계를 분석
- 무언가를 **예측** 하려고 사용

## 선형 회귀
- Linear regression
    - 기계학습이란 본질적으로 'probably approximately correct'한 target 함수를 학습하는 과정이라 볼 수 있는데, <br>**선형회귀는 해당 target 함수를 선형의 함수로서 근사하는 방법**
    - Key question; 새로운 data가 생겼을 때, 그 data는 어디에 위치할 것인가? 
    - Linear regression의 전제 조건: 적절한 Linear function을 만들면 그 언저리에 있을 것이다

## 단순 선형 회귀
- 연속형 반응 변수 y와 설명 변수 x 하나를 갖는 모형
- 가정: 두 변수는 인과관계가 있고, x에 따라 y값이 변한다

1. 산점도 그리기
- 각 데이터 포인트들은 2차원의 산점도로 나타내어 Linearity를 가지는지 시각화하여 눈으로 확인할 수 있다
- 비선형 관계를 갖는다면 변수 변환 방법을 적용하여 선형 모형으로 적합하는 것이 가능

2. 회귀계수 추정 
    1. 최소제곱법
    2. 최대우도추정법

3. 유의성 검정
- 모형 유의성: 모형 유의성은 모형에 포함되는 모든 기울기가 0인지 검정하는 분산 분석 문제
- 계수 유의성: 각 계수 값이 0인지 검정하는 T-검정 문제<br>
=> 단순 선형 회귀모형은 설명 변수가 하나 -> 모형 유의성과 계수 유의성 검정이 같음
- 회귀모형 유의성: 회귀모형 유의성은 (모든 기울기) = 0 을 검정하는 것과 같음
- 회귀계수 유의성: 회귀모형 유의성은 모형에 속한 모든 기울기가 0인지 아닌지를 검증했음. 하지만 모형이 유의미하다고 해도 각 기울기가 모두 유의미하다고 말할 수 업음(두 번의 검증 과정) 따라서 각 회귀 계소에 대한 유의성 검정을 통해 각 변수의 중요도 및 유의성을 확인할 수 있다. 이떄 각 기울기 유의성은 T-검정을 통해 얻을 수 있음

4. 회귀모형의 평가
- 평균제곱근 오차 RMSE는 추정 모형의 예측 정확도 평가를 위한 지표

## 다중 선형 회귀
- 단순 선형 회귀모형의 확장으로 연속형 변수 하나에 설명 변수가 둘 이상인 모형
- 당연히 추가로 검토해야할 문제가 생김
    - 설명 변수의 정보 중첩으로 발생하는 **다중공선성**문제
    - 너무 많은 설명 변수를 포함해 발생하는 **차원의 저주**문제

- 다중공선성: 모형에 포함된 설명 변수의 정보 중첩(상관관계를 가짐)으로 발생
- 범주형 설명 변수: 다수의 설명 변수를 사용하면 범주형 설명 변수가 모형에 포함되는 경우가 존재
- 변수 선택: 너무 많은 변수는 모형 과적합 야기<br>
-> simple linear regression과 동일하게 진행
    1. scatter plot이 가능하다면 plot으로 선형성 확인
    2. 회귀계수 추정
    3. 유의성 검정
    4. 평가

## 회귀모형의 가정 진단
- 회귀모형은 반응 변수와 설명 변수의 선형 관계를 전제로 함
- 또한 오차에 대한 독립성, 정규성, 등분산성 가정을 전제로 함
- 가정 진단: 내가 만든 linear regression 모델이 그래도 어느 정도 논리적으로 신빙성이 있습니다를 주장하기 위한 최소한의 근거

### 선형성 진단
- 가장 기초가 되는 진단: 반응 변수와 설명 변수가 선형 관계임을 기본으로 하기 떄문
- scatter plot을 통해 서로 선형 관계인지를 먼저 확인
- 상관계수를 이용하면 비선형 상관계수는 알 수 없지만 선형 관계의 정도 및 유의성을 알 수 있음

### 오차항의 독립성 진단
- 오차의 독립성 문제는 관측치가 서로 상관되어 있을 때 발생 가능
- 시간에 따라 관측된 자료의 경우 데이터가 시점 값에 영향을 주기도 함
- 잔차 그래프, ACF그래프, Durbin-Watson 통계량으로 독립성 문제 진단 가능 

### 오차항의 등분산성 진단
- 잔차 그래프와 등분산성 검정을 통해 알 수 있음
- 잔차 그래프가 일정한 추세를 갖는 경우 등분산성 가정을 만족하지 않을 수 있다
- 잔차의 등분산성 검정을 통해 등분산성을 만족하는지 확인 가능

### 오차항의 정규성 진단
- 잔차에 대한 Q-Q plot을 이용한 방법과 정규성 검정을 통한 방법이 존재
- Q-Q plot: 표준화된 잔차가 Q-Q plot의 대각선에 위치할 시 정규성 가정을 만족한다고 볼 수 있음
- 정규성 검정: K-S통계량, Cramer-von Mises 통계량 등을 이용 가능

## 회귀모형의 평가

### 평균제곱오차
- MSE 또는 MSD라고도 함
- 이 값이 크면 모형의 예측력이 떨어짐을 의미하고, 작을 수록 더 정확한 예측을 한다는 것 

## 선형 회귀 분석의 주요 이슈
- 번주형 설명 범수가 존재하는 경우
- 데이터에 이상치가 존재하는 경우
- 독립 변수 간 선형 상관관계가 존재하는 경우

## dummy 변수
- qualitative variable(질적 설명 변수)를 포함한 모형은 dummy variable(가변수) 또는 indicator variable(지시 변수) 형태로 변수를 변환해 모형에 포함하는 절차가 필요
- 수치로 표현되지 않는 경우, 이를 모델에 포함하고 싶은 경우
- ex) MBTI라면 0~15 숫자로 표현 가능 
-> 해당 feature가 가진 진정한 의미를 잃어버릴 수 있고, 논리 비양 생길 수 있는 단점 존재

## 이상치
- 관찰된 데이터의 속성과 많이 동떨어진 데이터

## 다중공선성
- 설명 변수들 간의 선형 종속이 심한 경우
- 설명 변수들 간 정보의 중첩이 발생한 것(완전한 선형 종속 관계가 발생한 경우)
